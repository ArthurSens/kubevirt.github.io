<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://kubevirt.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://kubevirt.io//" rel="alternate" type="text/html" /><updated>2020-09-25T15:28:15+00:00</updated><id>https://kubevirt.io//feed.xml</id><title type="html">KubeVirt.io</title><subtitle>Virtual Machine Management on Kubernetes</subtitle><entry><title type="html">KubeVirt v0.33.0</title><link href="https://kubevirt.io//2020/changelog-v0.33.0.html" rel="alternate" type="text/html" title="KubeVirt v0.33.0" /><published>2020-09-15T00:00:00+00:00</published><updated>2020-09-15T00:00:00+00:00</updated><id>https://kubevirt.io//2020/changelog-v0.33.0</id><content type="html" xml:base="https://kubevirt.io//2020/changelog-v0.33.0.html">&lt;h2 id=&quot;v0330&quot;&gt;v0.33.0&lt;/h2&gt;

&lt;p&gt;Released on: Tue Sep 15 14:46:00 2020 +0000&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[PR #3226][vatsalparekh] Added tests to verify custom pciAddress slots and function&lt;/li&gt;
  &lt;li&gt;[PR #4048][davidvossel] Improved reliability for failed migration retries&lt;/li&gt;
  &lt;li&gt;[PR #3585][mhenriks] ‚Äúvirtctl image-upload pvc ‚Ä¶‚Äù will create the PVC if it does not exist&lt;/li&gt;
  &lt;li&gt;[PR #3945][xpivarc] KubeVirt is now being built with Go1.13.14&lt;/li&gt;
  &lt;li&gt;[PR #3845][ArthurSens] action required: The domain label from VMI metrics is being removed and may break dashboards that use the domain label to identify VMIs. Use name and namespace labels instead&lt;/li&gt;
  &lt;li&gt;[PR #4011][dhiller] ppc64le arch has been disabled for the moment, see https://github.com/kubevirt/kubevirt/issues/4037&lt;/li&gt;
  &lt;li&gt;[PR #3875][stu-gott] Resources created by KubeVirt are now labelled more clearly in terms of relationship and role.&lt;/li&gt;
  &lt;li&gt;[PR #3791][ashleyschuett] make node as kubevirt.io/schedulable=false on virt-handler restart&lt;/li&gt;
  &lt;li&gt;[PR #3998][vladikr] the local provider is usable again.&lt;/li&gt;
  &lt;li&gt;[PR #3290][maiqueb] Have virt-handler (KubeVirt agent) create the tap devices on behalf of the virt-launchers.&lt;/li&gt;
  &lt;li&gt;[PR #3957][AlonaKaplan] virt-launcher support Ipv6 on dual stack cluster.&lt;/li&gt;
  &lt;li&gt;[PR #3952][davidvossel] Fixes rare situation where vmi may not properly terminate if failure occurs before domain starts.&lt;/li&gt;
  &lt;li&gt;[PR #3973][xpivarc] Fixes VMs with clock.timezone set.&lt;/li&gt;
  &lt;li&gt;[PR #3923][danielBelenky] Add support to configure QEMU I/O mode for VMIs&lt;/li&gt;
  &lt;li&gt;[PR #3889][rmohr] The status fields for our CRDs are now protected on normal PATCH and PUT operations.The /status subresource is now used where possible for status updates.&lt;/li&gt;
  &lt;li&gt;[PR #3568][xpivarc] Guest swap metrics available&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kubeü§ñ</name></author><category term="releases" /><category term="release notes" /><category term="changelog" /><summary type="html">v0.33.0</summary></entry><entry><title type="html">KubeVirt v0.32.0</title><link href="https://kubevirt.io//2020/changelog-v0.32.0.html" rel="alternate" type="text/html" title="KubeVirt v0.32.0" /><published>2020-08-11T00:00:00+00:00</published><updated>2020-08-11T00:00:00+00:00</updated><id>https://kubevirt.io//2020/changelog-v0.32.0</id><content type="html" xml:base="https://kubevirt.io//2020/changelog-v0.32.0.html">&lt;h2 id=&quot;v0320&quot;&gt;v0.32.0&lt;/h2&gt;

&lt;p&gt;Released on: Tue Aug 11 19:21:56 2020 +0000&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[PR #3921][vladikr] use correct memory units in libvirt xml&lt;/li&gt;
  &lt;li&gt;[PR #3893][davidvossel] Adds recurring period that resyncs virt-launcher domains with virt-handler&lt;/li&gt;
  &lt;li&gt;[PR #3880][sgarbour] Better error message when input parameters are not the expected number of parameters for each argument. Help menu will popup in case the number of parameters is incorrect.&lt;/li&gt;
  &lt;li&gt;[PR #3785][xpivarc] Vcpu wait metrics available&lt;/li&gt;
  &lt;li&gt;[PR #3642][vatsalparekh] Add a way to update VMI Status with latest Pod IP for Masquerade bindings&lt;/li&gt;
  &lt;li&gt;[PR #3636][ArthurSens] Adds kubernetes metadata.labels as VMI metrics‚Äô label&lt;/li&gt;
  &lt;li&gt;[PR #3825][awels] Virtctl now prints error messages from the response body on upload errors.&lt;/li&gt;
  &lt;li&gt;[PR #3830][davidvossel] Fixes re-establishing domain notify client connections when domain notify server restarts due to an error event.&lt;/li&gt;
  &lt;li&gt;[PR #3778][danielBelenky] Do not emit a SyncFailed event if we fail to sync a VMI in a final state&lt;/li&gt;
  &lt;li&gt;[PR #3803][andreabolognani] Not sure what to write here (see above)&lt;/li&gt;
  &lt;li&gt;[PR #2694][rmohr] Use native go libraries for selinux to not rely on python-selinux tools like semanage, which are not always present.&lt;/li&gt;
  &lt;li&gt;[PR #3692][victortoso] QEMU logs can now be fetched from outside the pod&lt;/li&gt;
  &lt;li&gt;[PR #3738][enp0s3] Restrict creation of VMI if it has labels that are used internally by Kubevirt components.&lt;/li&gt;
  &lt;li&gt;[PR #3725][danielBelenky] The tests binary is now part of the release and can be consumed from the GitHub release page.&lt;/li&gt;
  &lt;li&gt;[PR #3684][rmohr] Log if critical devices, like kvm, which virt-handler wants to expose are not present on the node.&lt;/li&gt;
  &lt;li&gt;[PR #3166][petrkotas] Introduce new virtctl commands:&lt;/li&gt;
  &lt;li&gt;[PR #3708][andreabolognani] Make qemu work on GCE by pulling in a fix for https://bugzilla.redhat.com/show_bug.cgi?id=1822682&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kubeü§ñ</name></author><category term="releases" /><category term="release notes" /><category term="changelog" /><summary type="html">v0.32.0</summary></entry><entry><title type="html">Import virtual machine from oVirt</title><link href="https://kubevirt.io//2020/Import-VM-from-oVirt.html" rel="alternate" type="text/html" title="Import virtual machine from oVirt" /><published>2020-08-06T00:00:00+00:00</published><updated>2020-08-06T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Import-VM-from-oVirt</id><content type="html" xml:base="https://kubevirt.io//2020/Import-VM-from-oVirt.html">&lt;h2 id=&quot;about-vm-import-operator&quot;&gt;About vm-import-operator&lt;/h2&gt;
&lt;p&gt;Virtual machine import operator makes life easier for users who want to migrate their virtual machine workload from different infrastructures to KubeVirt. Currently the operator supports migration from oVirt only. The operator is configurable so user can define how the storage or network should be mapped. For the disk import vm import operator is using the &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer&quot;&gt;CDI&lt;/a&gt;, so in order to have the vm import working you must have both KubeVirt and CDI installed.&lt;/p&gt;

&lt;h3 id=&quot;import-rules&quot;&gt;Import rules&lt;/h3&gt;
&lt;p&gt;Before the import process is initiated we run validation of the source VM, to be sure the KubeVirt will run the source VM smoothly. We have many &lt;a href=&quot;https://github.com/kubevirt/vm-import-operator/blob/master/docs/rules.md&quot;&gt;rules&lt;/a&gt; defined including storage, network and the VM. You will see all warning messages in the conditions field. For example:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-11T11:13:31Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-11T11:13:31Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;specifies&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IO&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Threads:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NUMA&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tune&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;secified:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;interleave'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerificationReportedWarnings&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerified&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;supported-guest-operating-systems&quot;&gt;Supported Guest Operating Systems&lt;/h3&gt;
&lt;p&gt;We support following guest operating systems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red Hat Enterprise Linux 6&lt;/li&gt;
  &lt;li&gt;Red Hat Enterprise Linux 7&lt;/li&gt;
  &lt;li&gt;Red Hat Enterprise Linux 8&lt;/li&gt;
  &lt;li&gt;Microsoft Windows 10&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2012r2&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2016&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2019&lt;/li&gt;
  &lt;li&gt;CentOS Linux 6&lt;/li&gt;
  &lt;li&gt;CentOS Linux 7&lt;/li&gt;
  &lt;li&gt;CentOS Linux 8&lt;/li&gt;
  &lt;li&gt;Ubuntu 18.04&lt;/li&gt;
  &lt;li&gt;Fedora&lt;/li&gt;
  &lt;li&gt;openSUSE&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;setup-vm-import-operator&quot;&gt;Setup vm-import-operator&lt;/h2&gt;
&lt;p&gt;Source code for virtual machine import operator is hosted on github under &lt;a href=&quot;https://github.com/kubevirt&quot;&gt;KubeVirt&lt;/a&gt; organization. You can very easily deploy it on your Kubernetes by running following commands:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/namespace.yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/operator.yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/vmimportconfig_cr.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By default the operator is deployed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubevirt-hyperconverged&lt;/code&gt; namespace,
you can verify that the operator is deployed and running by running:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get deploy vm-import-controller &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kubevirt-hyperconverged
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you are using &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator/&quot;&gt;HCO&lt;/a&gt;, you don‚Äôt have to install it manually,
because the HCO takes care of that.&lt;/p&gt;

&lt;h2 id=&quot;importing-virtual-machine-from-ovirt&quot;&gt;Importing virtual machine from oVirt&lt;/h2&gt;
&lt;p&gt;In order to import a virtual machine from oVirt user must obtain credentials for the oVirt environment. oVirt environment is usually accessed using username, password and http URL. Note that you must provide CA certificate of your oVirt environment. If you have those - create a secret out of them:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;stringData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;apiUrl: https://engine-url/ovirt-engine/api&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;username: admin@internal&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;password: &quot;secretpassword&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;caCert: |&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;-----BEGIN CERTIFICATE-----&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;MIIEMjCCAxqgAwIBAgICEAAwDQYJKoZIhvcNAQELBQAwbDELMAkGA1UEBhMCVVMxJDAiBgNVBAoM&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;....&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;fFyt91ClrUtTE707IFnYdQQUiZ4zI0q+6pmw6+xx8mH5k8Ad6D71pF718xCM1NiBx/Cusg==&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;-----END CERTIFICATE-----&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another step to initiate the import is creating the mappings. The mappings has three categories - storage mapping, disk mapping and network mapping. For storage mapping user can define which oVirt storage domain will be mapped to which storage class. Disk mapping can override the storage mapping for specific disks. The network mappings map oVirt network to the kubernetes network. So here an simple example of mapping:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ResourceMapping&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm-mapping&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networkMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;storageMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystoragedomain&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystorageclass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above mapping maps &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/code&gt; which is in format of vNIC profile/network to the pod network and disks from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mystoragedomain&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mystorageclass&lt;/code&gt;. Once we have mapping and the secret, we can initiate the import by creating a VM import CR. You must provide the name of the mapping, secret, source VM and target VM name.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineImport&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;providerCredentialsSecret&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;resourceMapping&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm-mapping&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mycluster&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that it is also possible to use internal mappings, so the user can create the mappings inside the VM import CR, for example:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineImport&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;providerCredentialsSecret&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;mappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;networkMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;storageMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystoragedomain&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystorageclass&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mycluster&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let the operator do its work. You can explore the status by checking the status of the VM import CR&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;conditions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Validation completed successfully&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ValidationCompleted&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Valid&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;specifies&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IO&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Threads:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NUMA&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tune&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;secified:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;interleave'&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerificationReportedWarnings&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerified&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Copying virtual machine disks&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ProcessingCompleted&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Processing&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Virtual machine disks import done&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineReady&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Succeeded&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;dataVolumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm-26097887-1f4d-4718-961f-f5b63a49c3f5&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The import process goes through different stages. The first stage is the validation where HCO checks for unsupported mappings.
The others are for processing and reporting to provide VM and disks ready status.&lt;/p&gt;

&lt;h2 id=&quot;future&quot;&gt;Future&lt;/h2&gt;
&lt;p&gt;For future releases it is planned to support importing virtual machines from VMware, reporting Prometheus metrics and SR-IOV.&lt;/p&gt;</content><author><name>Ondra Machacek</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="import" /><category term="oVirt" /><summary type="html">About vm-import-operator Virtual machine import operator makes life easier for users who want to migrate their virtual machine workload from different infrastructures to KubeVirt. Currently the operator supports migration from oVirt only. The operator is configurable so user can define how the storage or network should be mapped. For the disk import vm import operator is using the CDI, so in order to have the vm import working you must have both KubeVirt and CDI installed.</summary></entry><entry><title type="html">Minikube KubeVirt addon</title><link href="https://kubevirt.io//2020/Minikube_KubeVirt_Addon.html" rel="alternate" type="text/html" title="Minikube KubeVirt addon" /><published>2020-07-20T00:00:00+00:00</published><updated>2020-07-20T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Minikube_KubeVirt_Addon</id><content type="html" xml:base="https://kubevirt.io//2020/Minikube_KubeVirt_Addon.html">&lt;h2 id=&quot;deploying-kubevirt-has-just-gotten-easier&quot;&gt;Deploying KubeVirt has just gotten easier!&lt;/h2&gt;
&lt;p&gt;With the latest release (v1.12) of
&lt;a href=&quot;https://minikube.sigs.k8s.io/docs/&quot;&gt;minikube&lt;/a&gt; we can now deploy KubeVirt with
a one-liner.&lt;/p&gt;

&lt;h2 id=&quot;deploy-minikube&quot;&gt;Deploy minikube&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Start minikube.  Since my host is Fedora 32 I will use --driver=kvm2 and
  I will also use --container-runtime=crio&lt;br /&gt;
    &lt;code&gt;minikube start --driver=kvm2 --container-runtime=cri-o&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/1.png&quot; width=&quot;115&quot; height=&quot;72&quot; itemprop=&quot;thumbnail&quot; alt=&quot;minikube start&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Check that kubectl client is working correctly&lt;br /&gt;
    &lt;code&gt;kubectl cluster-info&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/2.png&quot; width=&quot;115&quot; height=&quot;11&quot; itemprop=&quot;thumbnail&quot; alt=&quot;kubectl cluster-info&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Enable the minikube kubevirt addon&lt;br /&gt;
    &lt;code&gt;minikube addons enable kubevirt&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/3.png&quot; width=&quot;115&quot; height=&quot;10&quot; itemprop=&quot;thumbnail&quot; alt=&quot;minikube addons enable kubevirt&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Verify KubeVirt components have been deployed to the kubevirt namespace&lt;br /&gt;
    &lt;code&gt;kubectl get ns; kubectl get all -n kubevirt&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/4.png&quot; width=&quot;115&quot; height=&quot;77&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify KubeVirt namespace and components&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;success&quot;&gt;SUCCESS!&lt;/h3&gt;

&lt;p&gt;From here a user can proceed on to the
&lt;a href=&quot;/labs/kubernetes/lab1&quot;&gt;Kubevirt Laboratory 1: Use KubeVirt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;As you can see it is now much easier to deploy KubeVirt in a minikube
Kubernetes environment.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Chris Callegari</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="minikube" /><category term="addons" /><summary type="html">Deploying KubeVirt has just gotten easier! With the latest release (v1.12) of minikube we can now deploy KubeVirt with a one-liner.</summary></entry><entry><title type="html">KubeVirt v0.31.0</title><link href="https://kubevirt.io//2020/changelog-v0.31.0.html" rel="alternate" type="text/html" title="KubeVirt v0.31.0" /><published>2020-07-09T00:00:00+00:00</published><updated>2020-07-09T00:00:00+00:00</updated><id>https://kubevirt.io//2020/changelog-v0.31.0</id><content type="html" xml:base="https://kubevirt.io//2020/changelog-v0.31.0.html">&lt;h2 id=&quot;v0310&quot;&gt;v0.31.0&lt;/h2&gt;

&lt;p&gt;Released on: Thu Jul 9 16:08:18 2020 +0300&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[PR 3690][davidvossel] Update go-grpc dependency to v1.30.0 in order to improve stability&lt;/li&gt;
  &lt;li&gt;[PR 3628][AlonaKaplan] Avoid virt-handler crash in case of virt-launcher network configuration error&lt;/li&gt;
  &lt;li&gt;[PR 3635][jean-edouard] The ‚ÄúHostDisk‚Äù feature gate has to be enabled to use hostDisks&lt;/li&gt;
  &lt;li&gt;[PR 3641][vatsalparekh] Reverts kubevirt/kubevirt#3488 because CI seems to have merged it without all tests passing&lt;/li&gt;
  &lt;li&gt;[PR 3488][vatsalparekh] Add a way to update VMI Status with latest Pod IP for Masquerade bindings&lt;/li&gt;
  &lt;li&gt;[PR 3406][tomob] If a PVC was created by a DataVolume, it cannot be used as a Volume Source for a VM. The owning DataVolume has to be used instead.&lt;/li&gt;
  &lt;li&gt;[PR 3566][kraxel] added: tigervnc support for linux &amp;amp; windows&lt;/li&gt;
  &lt;li&gt;[PR 3529][jean-edouard] Enabling EFI will also enable Secure Boot, which requires SMM to be enabled.&lt;/li&gt;
  &lt;li&gt;[PR 3455][ashleyschuett] Add KubevirtConfiguration, MigrationConfiguration, DeveloperConfiguration and NetworkConfiguration to API-types&lt;/li&gt;
  &lt;li&gt;[PR 3520][rmohr] Fix hot-looping on the  VMI sync-condition if errors happen during the Scheduled phase of a VMI&lt;/li&gt;
  &lt;li&gt;[PR 3220][mhenriks] API and controller/webhook for VirtualMachineSnapshots&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kubeü§ñ</name></author><category term="releases" /><category term="release notes" /><category term="changelog" /><summary type="html">v0.31.0</summary></entry><entry><title type="html">Common-templates</title><link href="https://kubevirt.io//2020/Common_templates.html" rel="alternate" type="text/html" title="Common-templates" /><published>2020-07-01T00:00:00+00:00</published><updated>2020-07-01T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Common_templates</id><content type="html" xml:base="https://kubevirt.io//2020/Common_templates.html">&lt;h2 id=&quot;what-is-a-virtual-machine-template&quot;&gt;What is a virtual machine template?&lt;/h2&gt;

&lt;p&gt;The KubeVirt project provides a set of templates (https://github.com/kubevirt/common-templates) to create VMS to handle common usage scenarios. These templates provide a combination of some key factors that could be further customized and processed to have a Virtual Machine object. With common templates you can easily start in a few minutes many VMS with predefined hardware resources (e.g. number of CPUs, requested memory, etc.).&lt;/p&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Beware&lt;/p&gt;&lt;p&gt;common templates work only on OpenShift. Kubernetes doesn‚Äôt have support for templates.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;what-does-a-vm-template-cover&quot;&gt;What does a VM template cover?&lt;/h2&gt;

&lt;p&gt;The key factors which define a template are&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Guest Operating System (OS) This allows to ensure that the emulated hardware is compatible with the guest OS. Furthermore, it allows to maximize the stability of the VM, and allows performance optimizations. Currently common templates support RHEL 6, 7, 8, Centos 6, 7, 8, Fedora 31 and newer, Windows 10, Windows server 2008, 2012 R2, 2016, 2019. The &lt;a href=&quot;https://docs.ansible.com/ansible/latest/user_guide/playbooks.html&quot;&gt;Ansible playbook&lt;/a&gt; &lt;a href=&quot;https://github.com/kubevirt/common-templates/blob/master/generate-templates.yaml&quot;&gt;generate-templates.yaml&lt;/a&gt; describes all combinations of templates that should be generated.&lt;/li&gt;
  &lt;li&gt;Workload type of most virtual machines should be server or desktop to have maximum flexibility; the highperformance workload trades some of this flexibility (ioThreadsPolicy is set to shared) to provide better performances (e.g. IO threads).&lt;/li&gt;
  &lt;li&gt;Size (flavor) Defines the amount of resources (CPU, memory) to allocate to the VM. There are 4 sizes: tiny (1 core, 1 Gi memory), small (1 core, 2 Gi memory), medium (1 core, 4 Gi memory), large (2 cores, 8 Gi memory). If these predefined sizes don‚Äôt suit you, you can create a new template based on common templates via UI (choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Workloads&lt;/code&gt; in the left panel¬†¬ª press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtualization&lt;/code&gt;¬†¬ª press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtual Machine Templates&lt;/code&gt;¬†¬ª press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine Template&lt;/code&gt; blue button) or CLI (update yaml template and create new template).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/create_template.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create new template&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;accessing-the-virtual-machine-templates&quot;&gt;Accessing the virtual machine templates&lt;/h2&gt;
&lt;p&gt;If you installed KubeVirt using a &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator&quot;&gt;supported method&lt;/a&gt;, you should find the common templates preinstalled in the cluster. If you want to upgrade the templates, or install them from scratch, you can use one of the &lt;a href=&quot;https://github.com/kubevirt/common-templates/releases&quot;&gt;supported releases&lt;/a&gt;
There are two ways to install and configure templates:&lt;/p&gt;

&lt;h2 id=&quot;via-cli&quot;&gt;Via CLI:&lt;/h2&gt;

&lt;h6 id=&quot;to-install-the-templates&quot;&gt;To install the templates:&lt;/h6&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ export VERSION=&quot;v0.11.2&quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc create -f https://github.com/kubevirt/common-templates/releases/download/$VERSION/common-templates-$VERSION.yaml&lt;/code&gt;&lt;/p&gt;

&lt;h6 id=&quot;to-create-vm-from-template&quot;&gt;To create VM from template:&lt;/h6&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc process rhel8-server-tiny PVCNAME=mydisk NAME=rheltinyvm | oc apply -f -&lt;/code&gt;&lt;/p&gt;

&lt;h6 id=&quot;to-start-vm-from-created-object&quot;&gt;To start VM from created object:&lt;/h6&gt;
&lt;p&gt;The created object is now a regular VirtualMachine object and from now it can be controlled by accessing Kubernetes API resources. The preferred way to do this is to use virtctl tool.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ virtctl start rheltinyvm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;An alternative way to start the VM is with the oc patch command. Example:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc patch virtualmachine rheltinyvm --type merge -p '{&quot;spec&quot;:{&quot;running&quot;:true}}'&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As soon as VM starts, openshift creates a new type of object - &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualMachineInstance&lt;/code&gt;. It has a similar name to VirtualMachine.&lt;/p&gt;

&lt;h2 id=&quot;via-ui&quot;&gt;Via UI:&lt;/h2&gt;
&lt;p&gt;The Kubevirt project has an official plugin in OpenShift Cluster Console Web UI. This UI supports the creation of VMS using templates and template features - flavors and workload profiles.&lt;/p&gt;

&lt;h6 id=&quot;to-install-the-templates-1&quot;&gt;To install the templates:&lt;/h6&gt;

&lt;p&gt;Install OpenShift virtualization operator from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Operators&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OperatorHub&lt;/code&gt;. The operator-based deployment takes care of installing various components, including the common templates.&lt;/p&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/operator.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Install operator&quot; /&gt;
&lt;/div&gt;

&lt;h6 id=&quot;to-create-vm-from-template-1&quot;&gt;To create VM from template:&lt;/h6&gt;
&lt;p&gt;To create a VM from a template, choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Workloads&lt;/code&gt; in the left panel¬†¬ª press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtualization&lt;/code&gt;¬†¬ª press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine&lt;/code&gt; blue button¬†¬ª choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;New with Wizard&lt;/code&gt;. Next, you have to see &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine&lt;/code&gt; window&lt;/p&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/create_vm.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create vm from template&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;This wizard leads you through the basic setup of vm (like guest operating system, workload, flavor, ‚Ä¶). After vm is created you can start requested vm.&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;after the generation step (UI and CLI), VM objects and template objects have no relationship with each other besides the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vm.kubevirt.io/template: rhel8-server-tiny-v0.10.0&lt;/code&gt; label. This means that changes in templates do not automatically affect VMS, or vice versa.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;</content><author><name>Karel Simon</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="common-templates" /><summary type="html">What is a virtual machine template?</summary></entry><entry><title type="html">Migrate a sample Windows workload to Kubernetes using KubeVirt and CDI</title><link href="https://kubevirt.io//2020/win_workload_in_k8s.html" rel="alternate" type="text/html" title="Migrate a sample Windows workload to Kubernetes using KubeVirt and CDI" /><published>2020-06-22T00:00:00+00:00</published><updated>2020-06-22T00:00:00+00:00</updated><id>https://kubevirt.io//2020/win_workload_in_k8s</id><content type="html" xml:base="https://kubevirt.io//2020/win_workload_in_k8s.html">&lt;p&gt;The goal of this blog is to demonstrate that a web service can continue to run
after a Windows guest virtual machine providing the service is migrated from
MS Windows and Oracle VirtualBox to a guest virtual machine orchestrated by
Kubernetes and KubeVirt on a Fedora Linux host.  Yes!  It can be done!&lt;/p&gt;

&lt;h3 id=&quot;source-details&quot;&gt;Source details&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Host platform: Windows 2019 Datacenter&lt;/li&gt;
  &lt;li&gt;Virtualization platform: Oracle VirtualBox 6.1&lt;/li&gt;
  &lt;li&gt;Guest platform: Windows 2019 Datacenter (guest to be migrated)
&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;
&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;
&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Guest application: My favorite dotnet application
&lt;a href=&quot;https://jellyfin.org/&quot;&gt;Jellyfin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;target-details&quot;&gt;Target details&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Host platform: Fedora 32 with latest updates applied&lt;/li&gt;
  &lt;li&gt;Kubernetes cluster created&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubevirt.io/quickstart_minikube/&quot;&gt;KubeVirt&lt;/a&gt; and &lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/image-upload&quot;&gt;CDI&lt;/a&gt; installed in the Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;procedure&quot;&gt;Procedure&lt;/h2&gt;

&lt;h3 id=&quot;tasks-to-performed-on-source-host&quot;&gt;Tasks to performed on source host&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Before we begin let's take a moment to ensure the service is running and
  web browser accessible&lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-1.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Ensure application service is running&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-2.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Confirm web browser access&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Power down the guest virtual machine to ensure all changes to the
  filesystem are quiesced to disk.&lt;br /&gt;
    &lt;code&gt;VBoxManage.exe controlvm testvm poweroff&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-3.png&quot; width=&quot;115&quot; height=&quot;20&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Power down the guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Upload the guest virtual machine disk image to the Kubernetes cluster
  and a target DataVolume called testvm
    &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;code&gt;
      virtctl.exe image-upload dv testvm
      --size=14Gi
      --image-path=&quot;C:\Users\Administrator\VirtualBox VMs\testvm\testvm.vdi&quot;
    &lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-4.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Upload disk image&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Verify the PersistentVolumeClaim created via the DataVolume
  image upload in the previous step&lt;br /&gt;
    &lt;code&gt;
      kubectl describe pvc/testvm
    &lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-1.png&quot; width=&quot;125&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify PersistentVolumeClaim&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Create a guest virtual machine definition that references the
  DataVolume containing our guest virtual machine disk image&lt;br /&gt;
    &lt;code&gt;kubectl create -f vm_testvm.yaml&lt;/code&gt;
    &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-2.png&quot; width=&quot;125&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create the guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Expose the Jellyfin service in Kubernetes via a NodePort type
  service&lt;br /&gt;
    &lt;code&gt;
      kubectl create -f service_jellyfin.yaml
    &lt;/code&gt;
    &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-3.png&quot; width=&quot;100&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create NodePort service&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Let's verify the running guest virtual machine by using the virtctl
  command to open a vnc session to the MS Window console.  While we are here
  let's also open a web browser and confirm web browser access to the
  application.&lt;br /&gt;
    &lt;code&gt;virtctl vnc testvm&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-4.png&quot; width=&quot;125&quot; height=&quot;70&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify running guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-5.png&quot; width=&quot;125&quot; height=&quot;70&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Web browser access to application&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;task-to-performed-on-user-workstation&quot;&gt;Task to performed on user workstation&lt;/h3&gt;

&lt;ol&gt;
  And finally let's confirm web browser access via the Kubernetes service url.&lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-6.png&quot; width=&quot;125&quot; height=&quot;70&quot; alt=&quot;Web browser access to Kubernetes service&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;success&quot;&gt;SUCCESS!&lt;/h3&gt;

&lt;p&gt;Here we have successfully demonstrated how simple it can be to migrate an
existing MS Windows platform and application to Kubernetes control. For
questions feel free to join the conversation via one of the project forums.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h5 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h5&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-noteref&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-noteref&quot;&gt;
      Fedora virtio drivers need to be installed on Windows hosts or virtual
      machines that will be migrated into a Kubernetes environment. Drivers can
      be found
      &lt;a href=&quot;https://docs.fedoraproject.org/en-US/quick-docs/creating-windows-virtual-machines-using-virtio-drivers/&quot;&gt;
        here
      &lt;/a&gt;.
      &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:2&quot; role=&quot;doc-noteref&quot;&gt;
      Please note:
      &lt;br /&gt;
      &amp;#8226; Users without certificate authority trusted certificates added to
      the kubernetes api and cdi cdi-proxyuploader secret will require the
      &lt;code&gt;--insecure&lt;/code&gt; arg.
      &lt;br /&gt;
      &amp;#8226; Users without the uploadProxyURLOverride patch to the cdi
      cdiconfig.cdi.kubevirt.io/config crd will require the
      &lt;code&gt;--uploadProxyURL&lt;/code&gt; arg.
      &lt;br /&gt;
      &amp;#8226; Users need a correctly configured $HOME/.kube/config along with
      client authentication certificate.
      &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:3&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;/assets/2020-06-22-win_workload_in_k8s/vm_testvm.yaml&quot;&gt;
        vm_testvm.yaml
      &lt;/a&gt;: Virtual machine manifest
      &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:4&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;/assets/2020-06-22-win_workload_in_k8s/service_jellyfin.yaml&quot;&gt;
        service_jellyfin.yaml
      &lt;/a&gt;: Service manifest
      &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Chris Callegari</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="images" /><category term="storage" /><category term="windows" /><summary type="html">The goal of this blog is to demonstrate that a web service can continue to run after a Windows guest virtual machine providing the service is migrated from MS Windows and Oracle VirtualBox to a guest virtual machine orchestrated by Kubernetes and KubeVirt on a Fedora Linux host. Yes! It can be done!</summary></entry><entry><title type="html">KubeVirt v0.30.0</title><link href="https://kubevirt.io//2020/changelog-v0.30.0.html" rel="alternate" type="text/html" title="KubeVirt v0.30.0" /><published>2020-06-05T00:00:00+00:00</published><updated>2020-06-05T00:00:00+00:00</updated><id>https://kubevirt.io//2020/changelog-v0.30.0</id><content type="html" xml:base="https://kubevirt.io//2020/changelog-v0.30.0.html">&lt;h2 id=&quot;v0300&quot;&gt;v0.30.0&lt;/h2&gt;

&lt;p&gt;Released on: Fri Jun 5 12:19:57 2020 +0200&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tests: Many more test fixes&lt;/li&gt;
  &lt;li&gt;Security: Introduce a custom SELinux policy for virt-launcher&lt;/li&gt;
  &lt;li&gt;More user friendly IPv6 default CIDR for IPv6 addresses&lt;/li&gt;
  &lt;li&gt;Fix OpenAPI compatibility issues by switching to openapi-gen&lt;/li&gt;
  &lt;li&gt;Improved support for EFI boot (configurable OVMF path and test fixes)&lt;/li&gt;
  &lt;li&gt;Improved VMI IP reporting&lt;/li&gt;
  &lt;li&gt;Support propagation of annotations from VMI to pods&lt;/li&gt;
  &lt;li&gt;Support for more fine grained (NET_RAW( capability granting to virt-launcher&lt;/li&gt;
  &lt;li&gt;Support for eventual consistency with DataVolumes&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kubeü§ñ</name></author><category term="releases" /><category term="release notes" /><category term="changelog" /><summary type="html">v0.30.0</summary></entry><entry><title type="html">SELinux, from basics to KubeVirt</title><link href="https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt.html" rel="alternate" type="text/html" title="SELinux, from basics to KubeVirt" /><published>2020-05-25T00:00:00+00:00</published><updated>2020-05-25T00:00:00+00:00</updated><id>https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt</id><content type="html" xml:base="https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt.html">&lt;p&gt;SELinux is one of many security mechanisms leveraged by KubeVirt.&lt;br /&gt;
For an overview of KubeVirt security, please first read &lt;a href=&quot;/2020/KubeVirt-Security-Fundamentals.html&quot;&gt;this excellent article&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;selinux-101&quot;&gt;SELinux 101&lt;/h2&gt;

&lt;p&gt;At its core, SELinux is a whitelist-based security policy system intended to limit interactions between Linux processes and files. Simplified, it can be visualized as a ‚Äúsyscall firewall‚Äù.&lt;/p&gt;

&lt;p&gt;Policies are based on statically defined types, that can be assigned to files, processes and other objects.&lt;/p&gt;

&lt;p&gt;A simple policy example would be to allow a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/test&lt;/code&gt; program to read its &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/test.conf&lt;/code&gt; configuration file.&lt;/p&gt;

&lt;p&gt;The policy for that would include directives to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Assign types to files and processes, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_bin_t&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/test&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_conf_t&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/test.conf&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt; for instances of the test program&lt;/li&gt;
  &lt;li&gt;Configure a &lt;em&gt;transition&lt;/em&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_bin_t&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Allow &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt; processes to read &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_conf_t&lt;/code&gt; files.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-selinux-standard-reference-policy&quot;&gt;The SELinux standard Reference Policy&lt;/h2&gt;

&lt;p&gt;Since SELinux policies are whitelists, a setup running with the above policy would not be allowed to do anything, except for that test program.&lt;/p&gt;

&lt;p&gt;A policy for an entire Linux distribution as seen in the wild is made of millions of lines, which wouldn‚Äôt be practical to write and maintain on a per-distribution basis.&lt;/p&gt;

&lt;p&gt;That is why the &lt;a href=&quot;https://github.com/SELinuxProject/refpolicy&quot;&gt;Reference Policy&lt;/a&gt; (refpolicy) was written. The refpolicy implements various mechanisms to simplify policy writing, but also contains modules for most core Linux applications.&lt;/p&gt;

&lt;p&gt;Most use-cases can be addressed with the ‚Äústandard‚Äù refpolicy, plus optionally some custom modules for specific applications not covered by the Reference Policy.&lt;/p&gt;

&lt;p&gt;Limitations start to arise for use-cases that run the same binary multiple times concurrently, and expect instances to be isolated from each other. Virtualization is one of those use cases. Indeed if 2 virtual machines are running on the same system, it is usually desirable that one VM can‚Äôt see the resources of the other one.&lt;/p&gt;

&lt;p&gt;As an example, if qemu processes are labeled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_t&lt;/code&gt; and disk files are labeled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_disk_t&lt;/code&gt;, allowing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_t&lt;/code&gt; to read/write &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_disk_t&lt;/code&gt; files would allow all qemu processes to access all disk files.&lt;/p&gt;

&lt;p&gt;Another mechanism is necessary to provide VM isolation. That is what SELinux MCS addresses.&lt;/p&gt;

&lt;h2 id=&quot;selinux-multi-category-security-mcs&quot;&gt;SELinux Multi-Category Security (MCS)&lt;/h2&gt;

&lt;p&gt;Multi-Category Security, or MCS, provides the ability to dynamically add numerical IDs (called categories) to any SELinux type on any object (file/process/socket/‚Ä¶).&lt;/p&gt;

&lt;p&gt;Categories range from 0 to 1023. Since only 1024 unique IDs would be quite limiting, most virtualization-related applications combine 2 categories, which add up to about 500,000 combinations. It‚Äôs important to note that categories have no order, so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c42,c42&lt;/code&gt; is equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c42&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1,c2&lt;/code&gt; is equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c2,c1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In the example above, we can now:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dynamically compute a unique random category for each VM&lt;/li&gt;
  &lt;li&gt;Assign the corresponding categories to all VM resources, like qemu instance and disk files&lt;/li&gt;
  &lt;li&gt;Only allow access when all the involved resources have the same category number.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that is exactly what libvirt does when compiled with SELinux support, as shown in the diagram below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/libvirt.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: MCS can do a lot more, this article only describes the bits that are used by libvirt and kubernetes.&lt;/p&gt;

&lt;h3 id=&quot;mcs-and-containers&quot;&gt;MCS and containers&lt;/h3&gt;

&lt;p&gt;Another application that leverages MCS is Linux containers.&lt;/p&gt;

&lt;p&gt;In fact, containers use very few SELinux types and rely mostly on MCS to provide container isolation. For example, all the files and processes in container filesystems have the same SELinux types. For a non-super-privileged container, those types are usually &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;container_file_t&lt;/code&gt; for file and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;container_t&lt;/code&gt; for processes. Most operations are permitted within those types, and the categories are really what matters.&lt;/p&gt;

&lt;p&gt;As with libvirt, categories have to match for access to be granted, effectively blocking inter-container communication.&lt;/p&gt;

&lt;p&gt;Super-privileged containers however are exempt from categories. They use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spc_t&lt;/code&gt; SELinux type, which allows them to do pretty much anything, at least as far as SELinux is concerned.&lt;/p&gt;

&lt;p&gt;That is all defined as an SELinux module in the &lt;a href=&quot;https://github.com/containers/container-selinux&quot;&gt;container-selinux Github repository&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mcs-and-container-orchestrators&quot;&gt;MCS and container orchestrators&lt;/h3&gt;

&lt;p&gt;Container orchestrators add a level of management. They define pods of containers, and within a pod, cross-container communication is acceptable and often even necessary.&lt;/p&gt;

&lt;p&gt;Categories are therefore managed at the pod level, and all the containers that belong to the same pod are assigned the same categories, as illustrated by the following diagram.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/kubernetes.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;selinux-in-kubevirt&quot;&gt;SELinux in Kubevirt&lt;/h2&gt;

&lt;p&gt;Finally getting to KubeVirt, which relies on all of the above, as it runs libvirt in a container managed by a container orchestrator on SELinux-enabled systems.&lt;/p&gt;

&lt;p&gt;In that context, libvirt runs inside a regular container and can‚Äôt manage SELinux object like types and categories. However, MCS isolation is provided by the container orchestrator, and every VM runs in its own pod (virt-launcher). And since no 2 virt-launcher pods will ever have the same categories on a given node, SELinux isolation of VMs is guaranteed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/kubevirt.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: As some host configuration is usually required for VMs to run, each node also runs a super-privileged pod (virt-handler), dedicated to such operations.&lt;/p&gt;</content><author><name>Jed Lejosne</name></author><category term="news" /><category term="kubevirt" /><category term="kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="design" /><category term="architecture" /><category term="security" /><category term="libvirt" /><category term="qemu" /><summary type="html">SELinux is one of many security mechanisms leveraged by KubeVirt. For an overview of KubeVirt security, please first read this excellent article.</summary></entry><entry><title type="html">KubeVirt VM Image Usage Patterns</title><link href="https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns.html" rel="alternate" type="text/html" title="KubeVirt VM Image Usage Patterns" /><published>2020-05-12T00:00:00+00:00</published><updated>2020-05-12T00:00:00+00:00</updated><id>https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns</id><content type="html" xml:base="https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns.html">&lt;h1 id=&quot;building-a-vm-image-repository&quot;&gt;Building a VM Image Repository&lt;/h1&gt;

&lt;p&gt;You know what I hear a lot from new KubeVirt users?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúHow do I manage VM images with KubeVirt? There‚Äôs a million options and I have no idea where to start.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I agree. It‚Äôs not obvious. There are a million ways to use and manipulate VM images with KubeVirt. That‚Äôs by design. KubeVirt is meant to be as flexible as possible, but in the process I think we dropped the ball on creating some well defined workflows people can use as a starting point.&lt;/p&gt;

&lt;p&gt;So, that‚Äôs what I‚Äôm going to attempt to do. I‚Äôll show you how to make your images accessible in the cluster. I‚Äôll show you how to make a custom VM image repository for use within the cluster. And I‚Äôll show you how to use this at scale using the same patterns you may have used in AWS or GCP.&lt;/p&gt;

&lt;p&gt;The pattern we‚Äôll use here is‚Ä¶&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Import a base VM image into the cluster as an PVC&lt;/li&gt;
  &lt;li&gt;Use KubeVirt to create a new immutable custom image with application assets&lt;/li&gt;
  &lt;li&gt;Scale out as many VMIs as we‚Äôd like using the pre-provisioned immutable custom image.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Remember, this isn‚Äôt ‚Äúthe definitive‚Äù way of managing VM images in KubeVirt. This is just an example workflow to help people get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;importing-a-base-image&quot;&gt;Importing a Base Image&lt;/h2&gt;

&lt;p&gt;Let‚Äôs start with importing a base image into a PVC.&lt;/p&gt;

&lt;p&gt;For our purposes in this workflow, the base image is meant to be immutable. No VM will use this image directly, instead VMs spawn with their own unique copy of this base image. Think of this just like you would containers. A container image is immutable, and a running container instance is using a copy of an image instead of the image itself.&lt;/p&gt;

&lt;h3 id=&quot;step-0-install-kubevirt-with-cdi&quot;&gt;Step 0. Install KubeVirt with CDI&lt;/h3&gt;

&lt;p&gt;I‚Äôm not covering this. Use our documentation linked to below. Understand that CDI (containerized data importer) is the tool we‚Äôll be using to help populate and manage PVCs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/installation&quot;&gt;Installing KubeVirt&lt;/a&gt;
&lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/image-upload?id=install-cdi&quot;&gt;Installing CDI&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-1-create-a-namespace-for-our-immutable-vm-images&quot;&gt;Step 1. Create a namespace for our immutable VM images.&lt;/h3&gt;

&lt;p&gt;We‚Äôll give users the ability to clone VM images living on PVCs from this namespace to their own namespace, but not directly create VMIs within this namespace.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create namespace vm-images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-2-import-your-image-to-a-pvc-in-the-image-namespace&quot;&gt;Step 2. Import your image to a PVC in the image namespace&lt;/h3&gt;

&lt;p&gt;Below are a few options for importing. For each example, I‚Äôm using the Fedora Cloud qcow2 image that can be downloaded &lt;a href=&quot;https://download.fedoraproject.org/pub/fedora/linux/releases/31/Cloud/x86_64/images/Fedora-Cloud-Base-31-1.9.x86_64.qcow2&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you try these examples yourself, you‚Äôll need to download the &lt;strong&gt;Fedora-Cloud-Base-31-1.9.x86_64.qcow2&lt;/strong&gt; image file in your working directory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example: Import a local VM from your desktop environment using virtctl&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you don‚Äôt have ingress setup for the cdi-uploadproxy service endpoint (which you don‚Äôt if you‚Äôre reading this) we can set up a local port forward using kubectl. That gives a route into the cluster to upload the image. Leave the command below executing to open the port.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl port-forward &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; cdi service/cdi-uploadproxy 18443:443
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In a separate terminal upload the image over the port forward connection using the virtctl tool. Note that the size of the PVC must be the size of what the qcow image will expand to when converted to a raw image. In this case I chose 5 gigabytes as the PVC size.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;virtctl image-upload dv fedora-cloud-base-31 &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; vm-images  &lt;span class=&quot;nt&quot;&gt;--size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5Gi &lt;span class=&quot;nt&quot;&gt;--image-path&lt;/span&gt; Fedora-Cloud-Base-31-1.9.x86_64.qcow2  &lt;span class=&quot;nt&quot;&gt;--uploadproxy-url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://127.0.0.1:18443 &lt;span class=&quot;nt&quot;&gt;--insecure&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once that completes, you‚Äôll have a PVC in the vm-images namespace that contains the Fedora Cloud image.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME               STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base-31   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example: Import using a container registry&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If the image‚Äôs footprint is small like our Fedora Cloud Base qcow image, then it probably makes sense to use a container image registry to import our image from a container image to a PVC.&lt;/p&gt;

&lt;p&gt;In the example below, I start by building a container image with the Fedora Cloud Base qcow VM image in it, and push that container image to my container registry.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; Dockerfile
FROM scratch
ADD Fedora-Cloud-Base-31-1.9.x86_64.qcow2 /disk/
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;END
&lt;/span&gt;docker build &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; quay.io/dvossel/fedora:cloud-base-31 &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
docker push quay.io/dvossel/fedora:cloud-base-31
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next a CDI DataVolume is used to import the VM image into a new PVC from the container image you just uploaded to your container registry. Posting the DataVolume manifest below will result in a new 5 gigabyte PVC being created and the VM image being placed on that PVC in a way KubeVirt can consume it.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; fedora-cloud-base-31-datavolume.yaml
apiVersion: cdi.kubevirt.io/v1alpha1
kind: DataVolume
metadata:
  name: fedora-cloud-base-31
  namespace: vm-images
spec:
  source:
    registry:
      url: &quot;docker://quay.io/dvossel/fedora:cloud-base-31&quot;
  pvc:
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: 5Gi
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;END
&lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; fedora-cloud-base-31-datavolume.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can observe the CDI complete the import by watching the DataVolume object.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl describe datavolume fedora-cloud-base-31 &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
Status:
  Phase:     Succeeded
  Progress:  100.0%
Events:
  Type    Reason            Age                   From                   Message
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;            &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                   &lt;span class=&quot;nt&quot;&gt;-------&lt;/span&gt;
  Normal  ImportScheduled   2m49s                 datavolume-controller  Import into fedora-cloud-base-31 scheduled
  Normal  ImportInProgress  2m46s                 datavolume-controller  Import into fedora-cloud-base-31 &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;progress
  Normal  Synced            40s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x11 over 2m51s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  datavolume-controller  DataVolume synced successfully
  Normal  ImportSucceeded   40s                   datavolume-controller  Successfully imported into PVC fedora-cloud-base-31
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the import is complete, you‚Äôll see the image available as a PVC in your vm-images namespace. The PVC will have the same name given to the DataVolume.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME                   STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base-31   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example: Import an image from an http or s3 endpoint&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While I‚Äôm not going to provide a detailed example here, another option for importing VM images into a PVC is to host the image on an http server (or as an s3 object) and then use a DataVolume to import the VM image into the PVC from a URL.&lt;/p&gt;

&lt;p&gt;Replace the url in this example with one hosting the qcow2 image. More information about this import method can be found &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/datavolumes.md#https3registry-source&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kind: DataVolume
metadata:
  name: fedora-cloud-base-31
  namespace: vm-images
spec:
  &lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt;:
    http:
      url: http://your-web-server-here/images/Fedora-Cloud-Base-31-1.9.x86_64.qcow2
  pvc:
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: 5Gi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;provisioning-new-custom-vm-image&quot;&gt;Provisioning New Custom VM Image&lt;/h2&gt;

&lt;p&gt;The base image itself isn‚Äôt that useful to us. Typically what we really want is an immutable VM image preloaded with all our application related assets. This way when the VM boots up, it already has everything it needs pre-provisioned. The pattern we‚Äôll use here is to provision the VM image once, and then use clones of the pre-provisioned VM image as many times as we‚Äôd like.&lt;/p&gt;

&lt;p&gt;For this example, I want a new immutable VM image preloaded with an nginx webserver. We can actually describe this entire process of creating this new VM image using the single VM manifest below. Note that I‚Äôm starting the VM inside the vm-images namespace. This is because I want the resulting VM image‚Äôs cloned PVC to remain in our vm-images repository namespace.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;runStrategy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;RerunOnFailure&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;dataVolume&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-31-nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;#!/bin/sh&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;yum install -y nginx&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;systemctl enable nginx&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# removing instances ensures cloud init will execute again after reboot&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;rm -rf /var/lib/cloud/instances&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;shutdown now&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;dataVolumeTemplates&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-31-nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadWriteOnce&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-cloud-base-31&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are a few key takeaways from this manifest worth discussing.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Usage of &lt;strong&gt;runStrategy: ‚ÄúRerunOnFailure‚Äù&lt;/strong&gt;. This tells KubeVirt to treat the VM‚Äôs execution similar to a Kubernetes Job. We want the VM to continue retrying until the VM guest shuts itself down gracefully.&lt;/li&gt;
  &lt;li&gt;Usage of the &lt;strong&gt;cloudInitNoCloud volume&lt;/strong&gt;. This volume allows us to inject a script into the VM‚Äôs startup procedure. In our case, we want this script to install nginx, configure nginx to launch on startup, and then immediately shutdown the guest gracefully once that is complete.&lt;/li&gt;
  &lt;li&gt;Usage of the &lt;strong&gt;dataVolumeTemplates section&lt;/strong&gt;. This allows us to define a new PVC which is a clone of our fedora-cloud-base-31 base image. The resulting VM image attached to our VM will be a new image pre-populated with nginx.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After posting the VM manifest to the cluster, wait for the corresponding VMI to reach the Succeeded phase.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get vmi &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME                AGE     PHASE       IP            NODENAME
nginx-provisioner   2m26s   Succeeded   10.244.0.22   node01
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This tells us the VM successfully executed the cloud-init script which installed nginx and shut down the guest gracefully. A VMI that never shuts down or repeatedly fails means something is wrong with the provisioning.&lt;/p&gt;

&lt;p&gt;All that‚Äôs left now is to delete the VM and leave the resulting PVC behind as our immutable artifact. We do this by deleting the VM using the ‚Äìcascade=false option. This tells Kubernetes to delete the VM, but leave behind anything owned by the VM. In this case we‚Äôll be leaving behind the PVC that has nginx provisioned on it.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl delete vm nginx-provisioner &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images &lt;span class=&quot;nt&quot;&gt;--cascade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After deleting the VM, you can see the nginx provisioned PVC in your vm-images namespace.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME               STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base-31   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
fedora-31-nginx            Bound    local-pv-8dla23ds    5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;understanding-the-vm-image-repository&quot;&gt;Understanding the VM Image Repository&lt;/h2&gt;
&lt;p&gt;At this point we have a namespace, vm-images, that contains PVCs with our VM images on them. Those PVCs represent VM images in the same way AWS‚Äôs AMIs represent VM images and this &lt;strong&gt;vm-images namespace is our VM image repository.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Using CDI‚Äôs i&lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/clone-datavolume.md#how-to-clone-an-image-from-one-dv-to-another-one&quot;&gt;cross namespace cloning feature&lt;/a&gt;, VM‚Äôs can now be launched across multiple namespaces throughout the entire cluster using the PVCs in this ‚Äúrepository‚Äù. Note that non-admin users need a special RBAC role to allow for this cross namespace PVC cloning. Any non-admin user who needs the ability to access the vm-images namespace for PVC cloning will need the RBAC permissions outlined &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/RBAC.md#pvc-cloning&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Below is an example of the RBAC necessary to enable cross namespace cloning from the vm-images namespace to the default namespace using the default service account.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi-cloner&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cdi.kubevirt.io&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;datavolumes/source&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;create&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;RoleBinding&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default-cdi-cloner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;subjects&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ServiceAccount&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;roleRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi-cloner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;apiGroup&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;horizontally-scaling-vms-using-custom-image&quot;&gt;Horizontally Scaling VMs Using Custom Image&lt;/h1&gt;

&lt;p&gt;Now that we have our immutable custom VM image, we can create as many VMs as we want using that custom image.&lt;/p&gt;

&lt;h2 id=&quot;example-scale-out-vmi-instances-using-the-custom-vm-image&quot;&gt;Example: Scale out VMI instances using the custom VM image.&lt;/h2&gt;

&lt;p&gt;Clone the custom VM image from the vm-images namespace into the namespace the VMI instances will be running in as a &lt;strong&gt;ReadOnlyMany&lt;/strong&gt; PVC. This will allow concurrent access to a single PVC.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DataVolume&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-rom&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-31-nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadOnlyMany&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, create a VirtualMachineInstanceReplicaSet that references the nginx-rom PVC as an ephemeral volume. With an ephemeral volume, KubeVirt will mount the PVC read only, and use a cow (copy on write) &lt;a href=&quot;https://kubevirt.io/user-guide/#/creation/disks-and-volumes?id=ephemeral&quot;&gt;ephemeral volume&lt;/a&gt; on local storage to back each individual VMI. This ephemeral data‚Äôs life cycle is limited to the life cycle of each VMI.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example manifest of a VirtualMachineInstanceReplicaSet starting 5 instances of our nginx server in separate VMIs.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineInstanceReplicaSet&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vmReplicaSet&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vmReplicaSet&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-image&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ephemeral&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-image&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;persistentVolumeClaim&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;claimName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-rom&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# add any custom logic you want to occur on startup here.&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;echo ‚Äúcloud-init script execution&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;example-launching-a-single-pet-vm-from-custom-image&quot;&gt;Example: Launching a Single ‚ÄúPet‚Äù VM from Custom Image&lt;/h2&gt;

&lt;p&gt;In the manifest below, we‚Äôre starting a new VM with a PVC cloned from our pre-provisioned VM image that contains the nginx server. When the VM boots up, a new PVC will be created in the VM‚Äôs namespace that is a clone of the PVC referenced in our vm-images namespace.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;running&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;dataVolume&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# add any custom logic you want to occur on startup here.&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;echo ‚Äúcloud-init script execution&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;dataVolumeTemplates&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadWriteOnce&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-31-nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;other-custom-creation-image-tools&quot;&gt;Other Custom Creation Image Tools&lt;/h1&gt;

&lt;p&gt;In my example I imported a VM base image into the cluster and used KubeVirt to provision a custom image with a technique that used cloud-init. This may or may not make sense for your use case. It‚Äôs possible you need to pre-provision the VM image before importing into the cluster at all.&lt;/p&gt;

&lt;p&gt;If that‚Äôs the case, I suggest looking into two tools.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://packer.io/docs/builders/qemu.html&quot;&gt;Packer.io using the qemu builder&lt;/a&gt;. This allows you to automate building custom images on your local machine using configuration files that describe all the build steps. I like this tool because it closely matches the Kubernetes ‚Äúdeclarative‚Äù approach.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://libguestfs.org/virt-customize.1.html&quot;&gt;Virt-customize&lt;/a&gt; is a cli tool that allows you to customize local VM images by injecting/modifying files on disk and installing packages.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://linux.die.net/man/1/virt-install&quot;&gt;Virt-install&lt;/a&gt; is a cli tool that allows you to automate a VM install as if you were installing it from a cdrom. You‚Äôll want to look into using a kickstart file to fully automate the process.&lt;/p&gt;

&lt;p&gt;The resulting VM image artifact created from any of these tools can then be imported into the cluster in the same way we imported the base image earlier in this document.&lt;/p&gt;</content><author><name>David Vossel</name></author><category term="news" /><category term="kubevirt" /><category term="kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="images" /><category term="storage" /><summary type="html">Building a VM Image Repository</summary></entry></feed>